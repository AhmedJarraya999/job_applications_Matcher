{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensimNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jaray\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\jaray\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\jaray\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Using cached gensim-4.3.2-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"extracted_entities_resume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Highest degree', 'Degrees', 'Major', 'Skill']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jenkins, prometheus, grafana, sonarqube, junit, openstack, deployment, web development, spring boot, angular, containers, kubernetes, docker, ansible, git, mysql, java, symfony, html, css, agile project management, groovy, design, azure, terraform, windows, debian, ubuntu, github, gitlab, .net, operating system, code, programming languages, database, engineering, computer architecture, communications']\n"
     ]
    }
   ],
   "source": [
    "skill_resume_values = df['Skill'].tolist()\n",
    "print(skill_resume_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example lists of skills\n",
    "skills_list1 = ['python', 'machine', 'learning', 'data', 'analysis']\n",
    "skills_list2 = ['python', 'machine', 'learning', 'data', 'analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Save the model\n",
    "model.save('sentence_transformer_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity_sbert_base_v2(skills_list1,skills_list2):\n",
    "    \"\"\"calculate similarity with SBERT all-mpnet-base-v2\"\"\"\n",
    "    model_path = \"sentence_transformer_model\"\n",
    "    model = SentenceTransformer(model_path)\n",
    "    #Encoding:\n",
    "    score = 0\n",
    "    sen = skills_list1+skills_list2\n",
    "    sen_embeddings = model.encode(sen)\n",
    "    for i in range(len(skills_list1)):\n",
    "        if skills_list1[i] in skills_list2:\n",
    "            score += 1\n",
    "        else:\n",
    "            if max(cosine_similarity([sen_embeddings[i]],sen_embeddings[len(skills_list1):])[0]) >= 0.4:\n",
    "                score += max(cosine_similarity([sen_embeddings[i]],sen_embeddings[len(skills_list1):])[0])\n",
    "    score = score/len(skills_list1)  \n",
    "    return round(score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(semantic_similarity_sbert_base_v2(skills_list1,skills_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the skills lists does not contain any embeddings.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "# Load Word2Vec model (pre-trained or trained on your data)\n",
    "# Make sure to provide the correct path to your Word2Vec model file\n",
    "word2vec_model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "# Tokenize skills and generate embeddings\n",
    "def get_embeddings(skill_list):\n",
    "    embeddings = []\n",
    "    for skill in skill_list:\n",
    "        if skill in word2vec_model.wv:\n",
    "            embeddings.append(word2vec_model.wv[skill])\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Filter out skills without embeddings\n",
    "embeddings1 = get_embeddings(skills_list1)\n",
    "embeddings2 = get_embeddings(skills_list2)\n",
    "\n",
    "# Check if embeddings lists are not empty\n",
    "if embeddings1.size == 0 or embeddings2.size == 0:\n",
    "    print(\"One of the skills lists does not contain any embeddings.\")\n",
    "else:\n",
    "    # Aggregate token embeddings\n",
    "    agg_embedding1 = np.mean(embeddings1, axis=0)\n",
    "    agg_embedding2 = np.mean(embeddings2, axis=0)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity([agg_embedding1], [agg_embedding2])[0][0]\n",
    "    print(\"Similarity between the two lists of skills:\", similarity)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
